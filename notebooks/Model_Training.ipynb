{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f3d1cb7",
   "metadata": {},
   "source": [
    "# Baymax - Model Training\n",
    "\n",
    "### üìã **Notebook Overview**\n",
    "\n",
    "This notebook implements a comprehensive model training for the **MHP Processed dataset**, which assesses mental health status across three dimensions:\n",
    "- 0: Stable\n",
    "- 1: Challenged\n",
    "- 2: Critical\n",
    "\n",
    "### üìä **Notebook Structure**\n",
    "\n",
    "This notebook is organized into **5 main parts**:\n",
    "- **Part 1:** Imports & Configuration\n",
    "- **Part 2:** Helper Functions\n",
    "- **Part 3:** Model Definitions\n",
    "- **Part 4:** Training Pipeline\n",
    "- **Part 5:** Baymax Model Training Execution\n",
    "\n",
    "### ü§ñ **Models Trained**\n",
    "\n",
    "**Traditional Machine Learning (6 models)**:\n",
    "- Logistic Regression\n",
    "- Gradient Boosting\n",
    "- K-Nearest Neighbors (KNN)\n",
    "- Random Forest\n",
    "- Decision Tree\n",
    "- Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6d4cb0",
   "metadata": {},
   "source": [
    "## Part 1: Imports & Configuration\n",
    "\n",
    "This section sets up the foundation for the entire training pipeline.\n",
    "\n",
    "### What This Cell Does:\n",
    "\n",
    "1. **Imports all required libraries:**\n",
    "   - Standard libraries (`warnings`, `time`, `pathlib`)\n",
    "   - Data science libraries (`numpy`, `pandas`)\n",
    "   - Visualization libraries (`matplotlib`, `seaborn`)\n",
    "   - Machine learning libraries (`scikit-learn`)\n",
    "   - Utilities (`joblib`)\n",
    "\n",
    "2. **Sets global configurations:**\n",
    "   - Random seed (`RANDOM_STATE = 42`) for reproducibility\n",
    "   - Cross-validation strategy (3-fold Stratified K-Fold)\n",
    "\n",
    "3. **Defines directory structure:**\n",
    "   - Input path pointing to the Baymax features directory containing `train.csv` and `test.csv`\n",
    "   - Output directories for results, models, and figures\n",
    "\n",
    "4. **Configures display settings:**\n",
    "   - Pandas display options (show all rows/columns)\n",
    "   - Matplotlib plotting configuration (DPI, style)\n",
    "   - Seaborn aesthetic settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "addeeca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTS & CONFIGURATION LOADED SUCCESSFULLY\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STANDARD LIBRARY IMPORTS\n",
    "# ============================================================================\n",
    "import os\n",
    "import warnings\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ============================================================================\n",
    "# DATA SCIENCE & NUMERICAL COMPUTING\n",
    "# ============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ============================================================================\n",
    "# VISUALIZATION\n",
    "# ============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ============================================================================\n",
    "# MACHINE LEARNING - SKLEARN\n",
    "# ============================================================================\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL PERSISTENCE\n",
    "# ============================================================================\n",
    "import joblib\n",
    "\n",
    "# ============================================================================\n",
    "# GLOBAL CONFIGURATION\n",
    "# ============================================================================\n",
    "# Random seed for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Cross-validation configuration\n",
    "CV = StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# ============================================================================\n",
    "# PATH CONFIGURATION\n",
    "# ============================================================================\n",
    "# Base Directory\n",
    "BASE_DIR = Path.cwd().parents[0]\n",
    "\n",
    "# Feature Input Path (single train/test split from Baymax preprocessing)\n",
    "FEATURES_DIR = BASE_DIR / \"features\"\n",
    "\n",
    "# Output Base Directories\n",
    "RESULTS_BASE = BASE_DIR / \"results\"\n",
    "MODELS_BASE  = BASE_DIR / \"models\"\n",
    "FIGURES_BASE = BASE_DIR / \"figures\"\n",
    "\n",
    "# Create output directories if they don't exist\n",
    "for p in [RESULTS_BASE, MODELS_BASE, FIGURES_BASE]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ============================================================================\n",
    "# DISPLAY SETTINGS\n",
    "# ============================================================================\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# Plotting Configuration\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams.update({\"figure.dpi\": 120})\n",
    "\n",
    "print(\"IMPORTS & CONFIGURATION LOADED SUCCESSFULLY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb01973",
   "metadata": {},
   "source": [
    "## Part 2: Helper Functions\n",
    "\n",
    "This section defines all utility functions used throughout the training pipeline.\n",
    "\n",
    "### What This Cell Does:\n",
    "\n",
    "1. **Metrics Computation:**\n",
    "   - `compute_metrics()` ‚Äî Calculates Accuracy, Precision, Recall, and F1 scores (weighted average) for multi-class evaluation\n",
    "\n",
    "2. **Visualization Functions:**\n",
    "   - `plot_and_save_confusion()` ‚Äî Generates and saves confusion matrix heatmaps as PNG files\n",
    "\n",
    "3. **Data Loading & Preprocessing:**\n",
    "   - `load_train_test_data()` ‚Äî Loads `train.csv` and `test.csv` from the Baymax features directory, drops rows with missing target values (`Mental Health Status Encoded`), and returns `X_train`, `y_train`, `X_test`, `y_test` as NumPy arrays\n",
    "\n",
    "4. **Model Persistence:**\n",
    "   - `save_model()` ‚Äî Saves a trained sklearn model to disk using `joblib`\n",
    "   - `load_model()` ‚Äî Loads a saved sklearn model from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff412fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HELPER FUNCTIONS LOADED SUCCESSFULLY\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# METRICS COMPUTATION\n",
    "# ============================================================================\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate classification metrics for model evaluation.\n",
    "\n",
    "    Args:\n",
    "        y_true: array-like, true labels\n",
    "        y_pred: array-like, predicted labels\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing Accuracy, Precision, Recall, and F1 scores\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"Accuracy\":  accuracy_score(y_true, y_pred),\n",
    "        \"Precision\": precision_score(y_true, y_pred, average=\"weighted\", zero_division=0),\n",
    "        \"Recall\":    recall_score(y_true, y_pred, average=\"weighted\", zero_division=0),\n",
    "        \"F1\":        f1_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# VISUALIZATION FUNCTIONS\n",
    "# ============================================================================\n",
    "def plot_and_save_confusion(y_true, y_pred, path, title):\n",
    "    \"\"\"\n",
    "    Generate and save a confusion matrix heatmap.\n",
    "\n",
    "    Args:\n",
    "        y_true: array-like, true labels\n",
    "        y_pred: array-like, predicted labels\n",
    "        path:   Path or str, file path to save the figure\n",
    "        title:  str, title for the plot\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(5, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax,\n",
    "                xticklabels=[\"Stable\", \"Challenged\", \"Critical\"],\n",
    "                yticklabels=[\"Stable\", \"Challenged\", \"Critical\"])\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"True\")\n",
    "    ax.set_title(title)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# DATA LOADING & PREPROCESSING\n",
    "# ============================================================================\n",
    "def load_train_test_data(features_dir):\n",
    "    \"\"\"\n",
    "    Load and preprocess training and testing data from the Baymax features directory.\n",
    "\n",
    "    Args:\n",
    "        features_dir: Path, directory containing train.csv and test.csv\n",
    "\n",
    "    Returns:\n",
    "        tuple: (X_train, y_train, X_test, y_test) as NumPy arrays\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If train.csv or test.csv does not exist\n",
    "    \"\"\"\n",
    "    train_path = features_dir / \"train.csv\"\n",
    "    test_path  = features_dir / \"test.csv\"\n",
    "\n",
    "    if not train_path.exists() or not test_path.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"Missing train.csv or test.csv in: {features_dir}\"\n",
    "        )\n",
    "\n",
    "    # Load data\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df  = pd.read_csv(test_path)\n",
    "\n",
    "    # Drop rows with missing target values\n",
    "    train_df = train_df.dropna(subset=[\"Mental Health Status Encoded\"])\n",
    "    test_df  = test_df.dropna(subset=[\"Mental Health Status Encoded\"])\n",
    "\n",
    "    # Separate features and target\n",
    "    X_train = train_df.drop(columns=[\"Mental Health Status Encoded\"]).values\n",
    "    y_train = train_df[\"Mental Health Status Encoded\"].astype(int).values\n",
    "    X_test  = test_df.drop(columns=[\"Mental Health Status Encoded\"]).values\n",
    "    y_test  = test_df[\"Mental Health Status Encoded\"].astype(int).values\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL PERSISTENCE\n",
    "# ============================================================================\n",
    "def save_model(model, model_path):\n",
    "    \"\"\"\n",
    "    Save a trained sklearn model to disk using joblib.\n",
    "\n",
    "    Args:\n",
    "        model:      trained sklearn estimator\n",
    "        model_path: Path or str, file path to save the model\n",
    "    \"\"\"\n",
    "    joblib.dump(model, model_path)\n",
    "\n",
    "\n",
    "def load_model(model_path):\n",
    "    \"\"\"\n",
    "    Load a saved sklearn model from disk.\n",
    "\n",
    "    Args:\n",
    "        model_path: Path or str, file path to the saved model\n",
    "\n",
    "    Returns:\n",
    "        Loaded sklearn estimator\n",
    "    \"\"\"\n",
    "    return joblib.load(model_path)\n",
    "\n",
    "\n",
    "print(\"HELPER FUNCTIONS LOADED SUCCESSFULLY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafbbae3",
   "metadata": {},
   "source": [
    "## Part 3: Model Definitions\n",
    "\n",
    "This section defines all six traditional machine learning model architectures with their default parameters.\n",
    "\n",
    "### What This Cell Does:\n",
    "\n",
    "**Traditional Machine Learning Models:**\n",
    "   - `get_ml_models()` ‚Äî Returns a dictionary of 6 ML models, each initialized with default parameters and a fixed `random_state` for reproducibility:\n",
    "     - **Logistic Regression** ‚Äî `max_iter=1000`, solver defaults\n",
    "     - **Gradient Boosting** ‚Äî Default ensemble of decision trees with boosting\n",
    "     - **K-Nearest Neighbors (KNN)** ‚Äî Distance-based classifier with default `k=5`\n",
    "     - **Random Forest** ‚Äî Ensemble of decision trees with bagging\n",
    "     - **Decision Tree** ‚Äî Single tree classifier\n",
    "     - **Support Vector Machine (SVM)** ‚Äî RBF kernel with probability estimates enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "879902d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL DEFINITIONS LOADED SUCCESSFULLY\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# TRADITIONAL MACHINE LEARNING MODELS\n",
    "# ============================================================================\n",
    "def get_ml_models(random_state=42):\n",
    "    \"\"\"\n",
    "    Get a dictionary of traditional machine learning models with default parameters.\n",
    "\n",
    "    Args:\n",
    "        random_state: int, random seed for reproducibility\n",
    "\n",
    "    Returns:\n",
    "        dict: Model name -> initialized sklearn estimator\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"Logistic Regression\": LogisticRegression(\n",
    "            max_iter=1000,\n",
    "            random_state=random_state\n",
    "        ),\n",
    "        \"Gradient Boosting\": GradientBoostingClassifier(\n",
    "            random_state=random_state\n",
    "        ),\n",
    "        \"KNN\": KNeighborsClassifier(),\n",
    "        \"Random Forest\": RandomForestClassifier(\n",
    "            random_state=random_state\n",
    "        ),\n",
    "        \"Decision Tree\": DecisionTreeClassifier(\n",
    "            random_state=random_state\n",
    "        ),\n",
    "        \"SVM\": SVC(\n",
    "            probability=True,\n",
    "            random_state=random_state\n",
    "        )\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"MODEL DEFINITIONS LOADED SUCCESSFULLY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43202050",
   "metadata": {},
   "source": [
    "## Part 4: Training Pipeline\n",
    "\n",
    "This section defines the comprehensive training workflow for all six traditional ML models.\n",
    "\n",
    "### What This Cell Does:\n",
    "\n",
    "**Traditional Machine Learning Pipeline:**\n",
    "   - `train_traditional_ml()` ‚Äî Trains all 6 ML models on the MHP Processed dataset in a single pass:\n",
    "     - Loads `train.csv` and `test.csv` from the features directory\n",
    "     - Creates output subdirectories for results and confusion matrix figures\n",
    "     - Iterates over each model and:\n",
    "       1. Fits the model on `X_train` / `y_train`\n",
    "       2. Predicts on `X_test`\n",
    "       3. Computes Accuracy, Precision, Recall, and F1 (weighted)\n",
    "       4. Saves the confusion matrix heatmap as a PNG\n",
    "       5. Saves the trained model to disk as a `.pkl` file\n",
    "     - Compiles all per-model metrics into a single results DataFrame\n",
    "     - Saves the results to a CSV in the results directory\n",
    "     - Returns the combined results DataFrame sorted by Accuracy (descending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97876186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING PIPELINE LOADED SUCCESSFULLY\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# TRADITIONAL MACHINE LEARNING TRAINING PIPELINE\n",
    "# ============================================================================\n",
    "def train_traditional_ml(features_dir, results_base, models_base, figures_base,\n",
    "                          dataset_name=\"MHP_Processed\", random_state=42):\n",
    "    \"\"\"\n",
    "    Train all traditional ML models on the MHP Processed dataset.\n",
    "\n",
    "    Args:\n",
    "        features_dir:  Path, directory containing train.csv and test.csv\n",
    "        results_base:  Path, base directory for saving result CSVs\n",
    "        models_base:   Path, base directory for saving trained models\n",
    "        figures_base:  Path, base directory for saving confusion matrix figures\n",
    "        dataset_name:  str, name of the dataset (used in plot titles and logs)\n",
    "        random_state:  int, random seed for reproducibility\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Results table with Accuracy, Precision, Recall, and F1\n",
    "                      for each model, sorted by Accuracy descending.\n",
    "                      Returns None if data loading fails.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"‚ñ∂  Training ML Models ‚Äî {dataset_name}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Create output directories\n",
    "    # ------------------------------------------------------------------\n",
    "    results_out = results_base / \"Machine Learning\"\n",
    "    models_out  = models_base\n",
    "    figures_out = figures_base / \"Machine Learning\"\n",
    "\n",
    "    for p in [results_out, models_out, figures_out]:\n",
    "        p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Load data\n",
    "    # ------------------------------------------------------------------\n",
    "    try:\n",
    "        X_train, y_train, X_test, y_test = load_train_test_data(features_dir)\n",
    "        print(f\"\\n  Train samples : {X_train.shape[0]}\")\n",
    "        print(f\"  Test  samples : {X_test.shape[0]}\")\n",
    "        print(f\"  Features      : {X_train.shape[1]}\")\n",
    "        print(f\"  Classes       : {sorted(set(y_train))}\\n\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"‚ö†Ô∏è  {e}\")\n",
    "        return None\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Get model definitions\n",
    "    # ------------------------------------------------------------------\n",
    "    models = get_ml_models(random_state)\n",
    "    results = []\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Train each model\n",
    "    # ------------------------------------------------------------------\n",
    "    for name, model in models.items():\n",
    "        print(f\"  - Training {name} ...\")\n",
    "\n",
    "        try:\n",
    "            # Train\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Predict\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            # Metrics\n",
    "            metrics = compute_metrics(y_test, y_pred)\n",
    "            results.append({\"Model\": name, **metrics})\n",
    "\n",
    "            # Confusion matrix\n",
    "            cm_filename = f\"{name.lower().replace(' ', '_')}_confusion.png\"\n",
    "            plot_and_save_confusion(\n",
    "                y_test, y_pred,\n",
    "                figures_out / cm_filename,\n",
    "                f\"{name} ‚Äî {dataset_name}\"\n",
    "            )\n",
    "\n",
    "            # Save model\n",
    "            model_filename = f\"{name.lower().replace(' ', '_')}.pkl\"\n",
    "            save_model(model, models_out / model_filename)\n",
    "\n",
    "            print(f\"    ‚úÖ Accuracy: {metrics['Accuracy']:.4f}  |  \"\n",
    "                  f\"F1: {metrics['F1']:.4f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"    ‚ö†Ô∏è  Error training {name}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Compile and save results\n",
    "    # ------------------------------------------------------------------\n",
    "    if not results:\n",
    "        print(\"‚ö†Ô∏è  No results were produced.\")\n",
    "        return None\n",
    "\n",
    "    results_df = pd.DataFrame(results).sort_values(\"Accuracy\", ascending=False)\n",
    "    results_df.to_csv(results_out / \"ml_results.csv\", index=False)\n",
    "    print(f\"\\n‚úÖ Results saved ‚Üí {results_out / 'ml_results.csv'}\")\n",
    "\n",
    "    return results_df\n",
    "\n",
    "\n",
    "print(\"TRAINING PIPELINE LOADED SUCCESSFULLY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e6d28d",
   "metadata": {},
   "source": [
    "## Part 5: Baymax Model Training Execution\n",
    "\n",
    "This section executes the full training workflow for the MHP Processed dataset and displays a final summary.\n",
    "\n",
    "### What This Cell Does:\n",
    "\n",
    "1. **Prints directory paths** ‚Äî Confirms the resolved feature input path and all output destinations before training begins.\n",
    "\n",
    "2. **Executes `train_traditional_ml()`** ‚Äî Triggers training of all 6 ML models using the preprocessed Baymax `train.csv` and `test.csv`.\n",
    "\n",
    "3. **Displays the results table** ‚Äî Prints the full results DataFrame (Model, Accuracy, Precision, Recall, F1) to the notebook output, sorted by Accuracy descending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b43145e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "================================================================================\n",
      "  BAYMAX ‚Äî TRADITIONAL MACHINE LEARNING\n",
      "================================================================================\n",
      "================================================================================\n",
      "\n",
      "üìÅ Directory Paths:\n",
      "   Features  : d:\\Programming\\Projects\\Baymax\\features\n",
      "   Results   : d:\\Programming\\Projects\\Baymax\\results\n",
      "   Models    : d:\\Programming\\Projects\\Baymax\\models\n",
      "   Figures   : d:\\Programming\\Projects\\Baymax\\figures\n",
      "\n",
      "‚è≥ Starting Traditional ML Training for Baymax ...\n",
      "\n",
      "============================================================\n",
      "‚ñ∂  Training ML Models ‚Äî MHP_Processed\n",
      "============================================================\n",
      "\n",
      "  Train samples : 1617\n",
      "  Test  samples : 405\n",
      "  Features      : 26\n",
      "  Classes       : [np.int64(0), np.int64(1), np.int64(2)]\n",
      "\n",
      "  - Training Logistic Regression ...\n",
      "    ‚úÖ Accuracy: 0.9111  |  F1: 0.9110\n",
      "  - Training Gradient Boosting ...\n",
      "    ‚úÖ Accuracy: 0.9136  |  F1: 0.9131\n",
      "  - Training KNN ...\n",
      "    ‚úÖ Accuracy: 0.9086  |  F1: 0.9074\n",
      "  - Training Random Forest ...\n",
      "    ‚úÖ Accuracy: 0.9235  |  F1: 0.9231\n",
      "  - Training Decision Tree ...\n",
      "    ‚úÖ Accuracy: 0.8494  |  F1: 0.8496\n",
      "  - Training SVM ...\n",
      "    ‚úÖ Accuracy: 0.9259  |  F1: 0.9256\n",
      "\n",
      "‚úÖ Results saved ‚Üí d:\\Programming\\Projects\\Baymax\\results\\Machine Learning\\ml_results.csv\n",
      "\n",
      "================================================================================\n",
      "  BAYMAX ‚Äî ML RESULTS SUMMARY\n",
      "================================================================================\n",
      "              Model  Accuracy  Precision   Recall       F1\n",
      "                SVM  0.925926   0.926270 0.925926 0.925584\n",
      "      Random Forest  0.923457   0.923771 0.923457 0.923138\n",
      "  Gradient Boosting  0.913580   0.913481 0.913580 0.913116\n",
      "Logistic Regression  0.911111   0.911441 0.911111 0.911037\n",
      "                KNN  0.908642   0.910892 0.908642 0.907373\n",
      "      Decision Tree  0.849383   0.850281 0.849383 0.849645\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# BAYMAX ‚Äî TRADITIONAL MACHINE LEARNING EXECUTION\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"=\" * 80)\n",
    "print(\"  BAYMAX ‚Äî TRADITIONAL MACHINE LEARNING\")\n",
    "print(\"=\" * 80)\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Print resolved directory paths\n",
    "# ------------------------------------------------------------------\n",
    "print(f\"\\nüìÅ Directory Paths:\")\n",
    "print(f\"   Features  : {FEATURES_DIR}\")\n",
    "print(f\"   Results   : {RESULTS_BASE}\")\n",
    "print(f\"   Models    : {MODELS_BASE}\")\n",
    "print(f\"   Figures   : {FIGURES_BASE}\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Run training pipeline\n",
    "# ------------------------------------------------------------------\n",
    "print(\"\\n‚è≥ Starting Traditional ML Training for Baymax ...\")\n",
    "\n",
    "results_ml = train_traditional_ml(\n",
    "    features_dir=FEATURES_DIR,\n",
    "    results_base=RESULTS_BASE,\n",
    "    models_base=MODELS_BASE,\n",
    "    figures_base=FIGURES_BASE,\n",
    "    dataset_name=\"MHP_Processed\",\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Display results table\n",
    "# ------------------------------------------------------------------\n",
    "if results_ml is not None:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"  BAYMAX ‚Äî ML RESULTS SUMMARY\")\n",
    "    print(\"=\" * 80)\n",
    "    print(results_ml.to_string(index=False))\n",
    "\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  No ML results produced for Baymax.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
